{\rtf1\ansi\ansicpg1252\cocoartf2509
\cocoatextscaling0\cocoaplatform0{\fonttbl\f0\fswiss\fcharset0 Helvetica;}
{\colortbl;\red255\green255\blue255;}
{\*\expandedcolortbl;;}
\margl1440\margr1440\vieww10800\viewh8400\viewkind0
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural\partightenfactor0

\f0\fs24 \cf0 #include <wb.h>\
\
#define wbCheck(stmt)                                                     \\\
  do \{                                                                    \\\
    cudaError_t err = stmt;                                               \\\
    if (err != cudaSuccess) \{                                             \\\
      wbLog(ERROR, "CUDA error: ", cudaGetErrorString(err));              \\\
      wbLog(ERROR, "Failed to run stmt ", #stmt);                         \\\
      return -1;                                                          \\\
    \}                                                                     \\\
  \} while (0)\
\
//@@ Define any useful program-wide constants here\
#define MASK_SIZE 3\
#define TILE_WIDTH 3\
#define SHARED_WIDTH 5\
#define RADIUS 1\
//@@ Define constant memory for device kernel here\
__constant__ float Mask[27];\
\
\
__global__ void conv3d(float *input, float *output, const int z_size,\
                       const int y_size, const int x_size) \{\
  //@@ Insert kernel code here\
  __shared__ float tile[SHARED_WIDTH][SHARED_WIDTH][SHARED_WIDTH];\
  // for my case block size cover the output size\
  int bx  = blockIdx.x * TILE_WIDTH; \
  int by = blockIdx.y * TILE_WIDTH; \
  int bz = blockIdx.z * TILE_WIDTH;\
  int tx = threadIdx.x; \
  int ty = threadIdx.y; \
  int tz = threadIdx.z;\
  \
  int ix = bx + tx - RADIUS;\
  int iy = by + ty - RADIUS;\
  int iz = bz + tz - RADIUS;\
  \
  if((ix >= 0 && ix < x_size) && (iy >= 0 && iy < y_size) && (iz >= 0 && iz < z_size))\{\
    tile[tx][ty][tz] = input[iz * x_size * y_size + iy * x_size + ix];\
  \}else\{\
    tile[tx][ty][tz] = 0.0;\
  \}\
  \
  __syncthreads();\
  \
  //finished loading the shared memory\
  \
  int ox = bx + tx; \
  int oy = by + ty; \
  int oz = bz + tz;\
  if((tx < TILE_WIDTH && ty < TILE_WIDTH) && tz < TILE_WIDTH)\{\
    float Pvalue = 0;\
    for(int i = 0; i < MASK_SIZE; i++)\{\
      for(int j = 0; j < MASK_SIZE; j++)\{\
        for(int k = 0; k < MASK_SIZE; k++)\{\
          Pvalue += tile[tx + i][ty + j][tz + k] * Mask[k * 9 + j * 3 + i]; \
        \}\
      \}\
    \}\
    if((ox < x_size && oy < y_size)&& oz < z_size)\{\
      output[oz * x_size * y_size + oy * x_size + ox] = Pvalue;\
    \}\
  \}\
\}\
\
int main(int argc, char *argv[]) \{\
  wbArg_t args;\
  int z_size;\
  int y_size;\
  int x_size;\
  int inputLength, kernelLength;\
  float *hostInput;\
  float *hostKernel;\
  float *hostOutput;\
  float *deviceInput;\
  float *deviceOutput;\
\
  args = wbArg_read(argc, argv);\
\
  // Import data\
  hostInput = (float *)wbImport(wbArg_getInputFile(args, 0), &inputLength);\
  hostKernel =\
      (float *)wbImport(wbArg_getInputFile(args, 1), &kernelLength);\
  hostOutput = (float *)malloc(inputLength * sizeof(float));\
\
  // First three elements are the input dimensions\
  z_size = hostInput[0];\
  y_size = hostInput[1];\
  x_size = hostInput[2];\
  wbLog(TRACE, "The input size is ", z_size, "x", y_size, "x", x_size);\
  assert(z_size * y_size * x_size == inputLength - 3);\
  assert(kernelLength == 27);\
\
  wbTime_start(GPU, "Doing GPU Computation (memory + compute)");\
\
  wbTime_start(GPU, "Doing GPU memory allocation");\
  //@@ Allocate GPU memory here\
  cudaMalloc((void **)&deviceInput, (inputLength - 3) * sizeof(float));\
  cudaMalloc((void **)&deviceOutput, (inputLength - 3) * sizeof(float));\
  // Recall that inputLength is 3 elements longer than the input data\
  // because the first  three elements were the dimensions\
  wbTime_stop(GPU, "Doing GPU memory allocation");\
\
  wbTime_start(Copy, "Copying data to the GPU");\
  //@@ Copy input and kernel to GPU here\
  cudaMemcpy(deviceInput, hostInput + 3, (inputLength - 3) * sizeof(float), cudaMemcpyHostToDevice);\
  cudaMemcpyToSymbol(Mask, hostKernel, kernelLength * sizeof(float));\
  // Recall that the first three elements of hostInput are dimensions and\
  // do\
  // not need to be copied to the gpu\
  wbTime_stop(Copy, "Copying data to the GPU");\
\
  wbTime_start(Compute, "Doing the computation on the GPU");\
  //@@ Initialize grid and block dimensions here\
  dim3 dimBlock(SHARED_WIDTH,SHARED_WIDTH,SHARED_WIDTH);\
  dim3 dimGrid(ceil(x_size/(1.0 *TILE_WIDTH)), ceil(y_size/(1.0 *TILE_WIDTH)), ceil(z_size/(1.0 *TILE_WIDTH)));\
  //@@ Launch the GPU kernel here\
  conv3d <<<dimGrid, dimBlock>>> (deviceInput, deviceOutput, z_size,y_size,x_size);\
  cudaDeviceSynchronize();\
  wbTime_stop(Compute, "Doing the computation on the GPU");\
\
  wbTime_start(Copy, "Copying data from the GPU");\
  //@@ Copy the device memory back to the host here\
   cudaMemcpy(hostOutput + 3, deviceOutput, (inputLength - 3) * sizeof(float), cudaMemcpyDeviceToHost);\
  // Recall that the first three elements of the output are the dimensions\
  // and should not be set here (they are set below)\
  wbTime_stop(Copy, "Copying data from the GPU");\
\
  wbTime_stop(GPU, "Doing GPU Computation (memory + compute)");\
\
  // Set the output dimensions for correctness checking\
  hostOutput[0] = z_size;\
  hostOutput[1] = y_size;\
  hostOutput[2] = x_size;\
  wbSolution(args, hostOutput, inputLength);\
\
  // Free device memory\
  cudaFree(deviceInput);\
  cudaFree(deviceOutput);\
\
  // Free host memory\
  free(hostInput);\
  free(hostOutput);\
  return 0;\
\}}